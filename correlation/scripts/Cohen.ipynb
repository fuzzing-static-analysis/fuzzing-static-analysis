{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af07807e-2d27-4b26-a4f7-b64bfc1ac02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# We collect the result after 23 hours\n",
    "TIME = 82800\n",
    "\n",
    "# the list of fuzzers included in 22th May, 2023 experiment\n",
    "fuzzer_list_1 = [\n",
    "    \"mopt\",\n",
    "    \"aflsmart\",\n",
    "    \"aflfast\",\n",
    "    \"aflplusplus\",\n",
    "    \"honggfuzz\",\n",
    "    \"libfuzzer\",\n",
    "    \"libafl\",\n",
    "    \"libafl_fuzzbench_cov_accounting\",\n",
    "    \"libafl_fuzzbench_explore\",\n",
    "    \"libafl_fuzzbench_mopt\",\n",
    "    \"libafl_fuzzbench_value_profile\",\n",
    "    \"libafl_fuzzbench_weighted\",\n",
    "    \"libafl_fuzzbench_cmplog\",\n",
    "    \"libafl_fuzzbench_naive\",\n",
    "    \"libafl_fuzzbench_fast\",\n",
    "    \"libafl_fuzzbench_rand_scheduler\",\n",
    "]\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./experiments/libafl0522.csv\", engine='python')\n",
    "selected = df[df['fuzzer'].isin(fuzzer_list_1)]\n",
    "selected = selected[['fuzzer', 'benchmark', 'edges_covered', 'time']]\n",
    "selected = selected[selected['time'] == TIME]\n",
    "\n",
    "benchmarks = selected.benchmark.unique()\n",
    "\n",
    "# Some experiment was not complete so we ran it again on 2th June, 2023\n",
    "fuzzer_list_2 = [\n",
    "    \"libafl_fuzzbench_ngram4\",\n",
    "    \"libafl_fuzzbench_ngram8\",\n",
    "    \"libafl_fuzzbench_naive_ctx\",\n",
    "]\n",
    "\n",
    "dff = pd.read_csv(\"./experiments/libafl0602.csv\", engine='python')\n",
    "selectedd = dff[dff['fuzzer'].isin(fuzzer_list_2)]\n",
    "selectedd = selectedd[['fuzzer', 'benchmark', 'edges_covered', 'time']]\n",
    "selectedd = selectedd[selectedd['time'] == TIME]\n",
    "\n",
    "# Lastly we added fix to grimoire fuzzer, so rerun the experiment on 25th September 2023 \n",
    "fuzzer_list_3 = [\n",
    "    \"libafl_fuzzbench_grimoire\",\n",
    "]\n",
    "dfff = pd.read_csv(\"./experiments/libafl0925.csv\", engine = 'python')\n",
    "selecteddd = dfff[dfff['fuzzer'].isin(fuzzer_list_3)]\n",
    "selecteddd = selecteddd[['fuzzer', 'benchmark', 'edges_covered', 'time']]\n",
    "selecteddd = selecteddd[selecteddd['time'] == TIME]\n",
    "\n",
    "# Concat them together\n",
    "result = pd.concat([selected, selectedd, selecteddd])\n",
    "fuzzer_list = fuzzer_list_1 + fuzzer_list_2 + fuzzer_list_3\n",
    "\n",
    "result.to_csv(\"result.csv\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b291d05-8c51-4e72-a88b-f21e28ddb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped the correlated features to ./cohen_features.json !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cohen\n",
    "# In[ ]:\n",
    "import matplotlib\n",
    "corr_result = dict()\n",
    "import warnings\n",
    "pd.options.mode.chained_assignment = None \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numpy import std, mean, sqrt, nan\n",
    "import numpy\n",
    "\n",
    "printf_debug = False\n",
    "\n",
    "# pooled deviation, this is needed to calculate cohen's d\n",
    "def pooled_dev(s1, s2):\n",
    "    l1 = len(s1)\n",
    "    l2 = len(s2)\n",
    "    \n",
    "    return sqrt((numpy.var(s1, ddof = 1) * (l1 - 1) + numpy.var(s2, ddof = 1) * (l2 - 1)) / (l1 + l2 - 2))\n",
    "\n",
    "# to color the graphs\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "# Cohen's d\n",
    "def cohen_d(fuzzer, x, y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    divisor = sqrt(((nx-1)*std(x, ddof=1) ** 2 + (ny-1)*std(y, ddof=1) ** 2) / dof)\n",
    "    d = (mean(x) - mean(y)) / divisor\n",
    "\n",
    "    wa = nx+ny\n",
    "    seki = nx * ny\n",
    "    nijo = d * d\n",
    "\n",
    "    # std error of cohen's d, from\n",
    "    # https://stats.stackexchange.com/questions/495015/what-is-the-formula-for-the-standard-error-of-cohens-d\n",
    "    # we didn't use it in the end\n",
    "    v = sqrt((wa / seki) + (nijo / (2 * (wa - 2))))\n",
    "\n",
    "    # for debug\n",
    "    # if numpy.isnan(v) or v == 0:\n",
    "    #     print(fuzzer, nx, ny, dof)\n",
    "    #     print(x, y)\n",
    "    return (d, divisor, v)\n",
    "\n",
    "plot = False\n",
    "\n",
    "def run_analysis(abs_path, property_data, filename):\n",
    "    if printf_debug:\n",
    "        print(\"Loading\", abs_path)\n",
    "    res_spearman = dict()\n",
    "    res_cohen = dict()\n",
    "    \n",
    "    for FUZZER in fuzzer_list:\n",
    "        points_removed = 0\n",
    "        points = dict()\n",
    "\n",
    "        property_v = []\n",
    "        for benchmark in benchmarks:\n",
    "            property_v.append(property_data[benchmark][1])\n",
    "\n",
    "        # Find the the ICQ Range\n",
    "        q75, q25 = np.percentile(property_v, [75 ,25])\n",
    "        x_iqr = q75 - q25\n",
    "        x_min = q25 - x_iqr * 1.5\n",
    "        x_max = q75 + x_iqr * 1.5\n",
    "\n",
    "        divisor = dict()\n",
    "        # print(filename, outlier_x, \"outliers\")\n",
    "        for benchmark in benchmarks:\n",
    "\n",
    "            property_rank, property_value = property_data[benchmark]\n",
    "            # Remove feature outliers\n",
    "            if property_value < x_min or property_value > x_max:\n",
    "               continue\n",
    "            for fuzzer in fuzzer_list:\n",
    "                if fuzzer == FUZZER:\n",
    "                    data = result[(result['benchmark'] == benchmark)]\n",
    "                    property_rank, property_value = property_data[benchmark]\n",
    "\n",
    "                    # Find out the rank\n",
    "                    data.loc[:, 'fuzzer_rank'] = data.loc[:, 'edges_covered'].rank(method = 'average')\n",
    "                    # This is the baseline data\n",
    "                    baseline = data[(data['fuzzer'] == 'libafl_fuzzbench_naive')]\n",
    "\n",
    "                    # Set for target fuzzer\n",
    "                    s1 = []\n",
    "                    # Set for the baseline (i.e. naive)\n",
    "                    s2 = []\n",
    "                    target_fuzzer = data[(data['fuzzer'] == fuzzer)]\n",
    "                    for v in target_fuzzer['edges_covered']:\n",
    "                        s1.append(v)\n",
    "                    for v in baseline['edges_covered']:\n",
    "                        s2.append(v)\n",
    "                        \n",
    "                    if len(s1) != 0 and fuzzer != 'libafl_fuzzbench_naive':\n",
    "                        cohend, divisor, v = cohen_d(fuzzer, s1, s2)\n",
    "                        points[benchmark] = (((divisor, cohend - 2*v, cohend, cohend + 2*v), property_value))\n",
    "\n",
    "        # ss.sort(key = lambda item: item[1])\n",
    "        X = []\n",
    "        \n",
    "        y = []\n",
    "        if len(points) == 0:\n",
    "            continue\n",
    "            \n",
    "        cmap = get_cmap(len(points.keys()))\n",
    "        points = {k: v for k, v in sorted(points.items(), key = lambda x: x[1][1])}\n",
    "        names = []\n",
    "        for i, (bch_name, ((divisor, l, cohend, h), property_value)) in enumerate(points.items()):\n",
    "            X.append(property_value)\n",
    "            y.append(cohend)\n",
    "            names.append(bch_name)\n",
    "            plt.scatter([property_value], [cohend], c = cmap(i), label = bch_name)\n",
    "\n",
    "        if printf_debug:\n",
    "            print(\"names\", names)\n",
    "            print(\"X\", X)\n",
    "            print(\"y\", y)\n",
    "        reg = np.polyfit(X, y, 1)\n",
    "        f = np.poly1d(reg)\n",
    "\n",
    "        # Plot the graph\n",
    "        plt.xlabel(\"program feature value\")\n",
    "        plt.ylabel(\"cohen d\")\n",
    "        filename_toshow = filename.replace(\"_ord.txt\", \"\")\n",
    "        fuzzername_toshow = FUZZER.replace(\"libafl_fuzzbench_\", \"\")\n",
    "        plt.title(\"{}-{}\".format(filename_toshow, fuzzername_toshow))\n",
    "        plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "        plt.plot(X, f(X), color = \"r\")\n",
    "        # print(f)\n",
    "        \n",
    "        from scipy import stats\n",
    "        import math\n",
    "        # print(stats.spearmanr(X, y))\n",
    "        cor_result = stats.pearsonr(X, y)\n",
    "        spearman_r = cor_result.statistic\n",
    "        pvalue = cor_result.pvalue\n",
    "        count = len(X)\n",
    "\n",
    "        res_spearman[FUZZER] = (spearman_r, pvalue)\n",
    "        plt.clf()\n",
    "    \n",
    "    for (key, (r, pvalue)) in res_spearman.items():\n",
    "        if (r >= 0.40 or r <= -0.40) and pvalue <= 0.05:\n",
    "            if key in corr_result:\n",
    "                corr_result[key].append((file, (r, pvalue)))\n",
    "            else:\n",
    "                corr_result[key] = [(file, (r, pvalue))]\n",
    "\n",
    "# Place the data in '../data' to load\n",
    "import os\n",
    "file_list = []\n",
    "for r, subdir, files in os.walk(\"../data\"):\n",
    "    for file in files:\n",
    "        abs_path = os.path.join(r, file)\n",
    "        file_list.append((abs_path, file))\n",
    "\n",
    "# we don't really need to sort but just for debug\n",
    "file_list.sort()\n",
    "for abs_path, file in file_list:\n",
    "    property_data = dict()\n",
    "    with open(abs_path) as f:\n",
    "        property_data = json.load(f)\n",
    "    assert(len(property_data) == 23)\n",
    "    run_analysis(abs_path, property_data, file)\n",
    "# In[ ]:\n",
    "\n",
    "available_features = dict()\n",
    "for k, v in corr_result.items():\n",
    "    if printf_debug:\n",
    "        print(\"Result: \")\n",
    "        print(\"key\", k)\n",
    "        print(\"value\", v)\n",
    "    available_features[k] = []\n",
    "    for item in v:\n",
    "        available_features[k].append(item[0].lstrip(\"../data/\"))\n",
    "\n",
    "with open(\"cohen_features.json\", 'w') as json_output:\n",
    "    json.dump(available_features, json_output)\n",
    "\n",
    "print(\"Dumped the correlated features to ./cohen_features.json !\")\n",
    "# print(corr_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79067a-c959-401e-bf8e-5b47829f622a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
